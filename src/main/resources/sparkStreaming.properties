#####################################################
#####################开发环境#########################
#####################################################

#######spark配置#####################

##发起的spark程序名
sparkJobName=FaceBodyNumDev

#实时统计频率
Durations.seconds=10

#reduce的task数目。通常的，reduce数目设置为core数目的2-3倍
spark.default.parallelism=8

#从kafka每个分区一批次拉取的数量
spark.streaming.kafka.maxRatePerPartition=50

spark.streaming.unpersist=true


#####kafka配置######################
brokers=cldmng01.lingda.com:9092,cldmng02.lingda.com:9092,cldmng02.lingda.com:9092
#topic=captureTopic_test
#topic=captureTopic_dev_3
topic=captureTopic_test
auto.offset.reset=largest
#group.id=statistics
group.id=statistics_vid
#group.id=tj_test
viddid.group.id=vid_did_test
vidvid.group.id=vid_vid_test



######zookeeper配置################
zkHost=cldmng01.lingda.com:2181,cldmng02.lingda.com:2181,cldmng02.lingda.com:2181


#####其它#########################
#数据保存天数
saveDays=365

#分表存储vid和did  分表数量
tablesNum=10

#文件存储路径
filePath=d://1.txt

#设备要过滤的tag集合
cameraidTags=100,200,300

#redis记录过期时间7天（秒）
expireSecond=604800


#####################################################
#####################测试环境#########################
#####################################################

#######spark配置#####################

##发起的spark程序名
#sparkJobName=FaceBodyNumTest
#
##实时统计频率
#Durations.seconds=10
#
##reduce的task数目。通常的，reduce数目设置为core数目的2-3倍
#spark.default.parallelism=15
#
##从kafka每个分区一批次拉取的数量
#spark.streaming.kafka.maxRatePerPartition=50
#
#spark.streaming.unpersist=true
#
#
######kafka配置######################
#brokers=yh-ambari01.lingda.com:6667,yh-ambari02.lingda.com:6667,yh-ambari03.lingda.com:6667
#topic=captureTopic_test
##topic=tianjun_test1
#auto.offset.reset=largest
#group.id=statistics_test
#viddid.group.id=vid_did_test
#
#
#
#
#######zookeeper配置################
#zkHost=yh-ambari03.lingda.com:2181,yh-ambari01.lingda.com:2181,yh-ambari02.lingda.com:2181
#
#
######其它#########################
##数据保存天数
#saveDays=365
#
##分表存储vid和did  分表数量
#tablesNum=10
#
##设备要过滤的tag集合
#cameraidTags=100,200,300
#
##redis记录过期时间7天（秒）
#expireSecond=604800


#####################################################
#####################正式环境#########################
#####################################################
#######spark配置#####################
#
##发起的spark程序名
#sparkJobName=FaceBodyNumProd
#
##实时统计频率
#Durations.seconds=10
#
##reduce的task数目。通常的，reduce数目设置为core数目的2-3倍
#spark.default.parallelism=50
#
##从kafka每个分区一批次拉取的数量
#spark.streaming.kafka.maxRatePerPartition=50
#
#spark.streaming.unpersist=true
#
#
######kafka配置######################
#brokers=192.168.2.102:6667,192.168.2.103:6667,192.168.2.105:6667
#topic=captureTopic
##topic=tianjun_test1
#auto.offset.reset=largest
#group.id=statistics
#viddid.group.id=vid_did
#
#
#
#
#######zookeeper配置################
#zkHost=192.168.2.102:2181,192.168.2.103:2181,192.168.2.105:2181
#
#
######其它#########################
##数据保存天数
#saveDays=365
#
##分表存储vid和did  分表数量
#tablesNum=10
#
##设备要过滤的tag集合
#cameraidTags=100,200,300
#
##redis记录过期时间7天（秒）
#expireSecond=604800